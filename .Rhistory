if(adhd3[ ,"GROUP"][i] == "Controls")
{
cat_v[i]<-"0"
}else{
cat_v[i]<-"1"
}
}
adhd3 <- data.frame(cat_v, adhd3)
Z <- adhd3[ ,-2]
Z <- apply(Z,2,as.numeric)
r <- Z[ ,1]
r <- as.vector(r)
adhd <- Z[ ,-1]
rm(list=c("adhd0", "adhd1", "adhd2", "adhd3"))
logitControl  <- trainControl(method="repeatedcv",number = 10,repeats = 1)
cv.model <- cv.glmnet(x=adhd, y=r, family= "binomial", alpha=1 )
plot(cv.model)
l.min <- cv.model$lambda.min
lasso_logistic.model <- glmnet(adhd, r, "binomial", alpha=1, lambda = l.min)
library(glmnet)
DATA <-  read.csv("train_data.csv")
adhd0 <- t(DATA)
adhd1 <- adhd0[-1, ]
#naming the colnames
colnames(adhd1) <- as.character(adhd1[1, ])
X <- apply(adhd1[,-1],2, as.numeric)
X <- data.frame(adhd1[ ,1],X)
adhd2 <- X[-1, ]
adhd3 <- as.matrix(adhd2)
colnames(adhd3)[1] <- "GROUP"
#defining control group=0
cat_v <- c()
for (i in 1:dim(adhd3)[1]){
if(adhd3[ ,"GROUP"][i] == "Controls")
{
cat_v[i]<-"0"
}else{
cat_v[i]<-"1"
}
}
adhd3 <- data.frame(cat_v, adhd3)
Z <- adhd3[ ,-2]
Z <- apply(Z,2,as.numeric)
r <- Z[ ,1]
r <- as.vector(r)
adhd <- Z[ ,-1]
rm(list=c("adhd0", "adhd1", "adhd2", "adhd3"))
# logitControl  <- trainControl(method="repeatedcv",number = 10,repeats = 1)
cv.model <- cv.glmnet(x=adhd, y=r, family= "binomial", alpha=1 )
plot(cv.model)
l.min <- cv.model$lambda.min
lasso_logistic.model <- glmnet(adhd, r, "binomial", alpha=1, lambda = l.min)
B <- lasso_logistic.model$beta
B <- lasso_logistic.model$beta
install.packages("Matrix")
install.packages("Matrix")
install.packages("Matrix")
install.packages("Matrix")
?predict
install.packages("e1071")
View(Z)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
library(glmnet)
DATA <-  read.csv("train_data.csv")
adhd0 <- t(DATA)
adhd1 <- adhd0[-1, ]
#naming the colnames
colnames(adhd1) <- as.character(adhd1[1, ])
X <- apply(adhd1[,-1],2, as.numeric)
X <- data.frame(adhd1[ ,1],X)
adhd2 <- X[-1, ]
adhd3 <- as.matrix(adhd2)
colnames(adhd3)[1] <- "GROUP"
#defining control group=0
cat_v <- c()
for (i in 1:dim(adhd3)[1]){
if(adhd3[ ,"GROUP"][i] == "Controls")
{
cat_v[i]<-"0"
}else{
cat_v[i]<-"1"
}
}
adhd3 <- data.frame(cat_v, adhd3)
Z <- adhd3[ ,-2]
Z <- apply(Z,2,as.numeric)
View(Z)
library(glmnet)
DATA <-  read.csv("train_data.csv")
adhd0 <- t(DATA)
adhd1 <- adhd0[-1, ]
#naming the colnames
colnames(adhd1) <- as.character(adhd1[1, ])
X <- apply(adhd1[,-1],2, as.numeric)
X <- data.frame(adhd1[ ,1],X)
adhd2 <- X[-1, ]
adhd3 <- as.matrix(adhd2)
colnames(adhd3)[1] <- "GROUP"
#defining control group=0
cat_v <- c()
for (i in 1:dim(adhd3)[1]){
if(adhd3[ ,"GROUP"][i] == "Controls")
{
cat_v[i]<-"0"
}else{
cat_v[i]<-"1"
}
}
adhd3 <- data.frame(cat_v, adhd3)
Z <- adhd3[ ,-2]
Z <- apply(Z,2,as.numeric)
colnames(Z)[1] <- "Group"
View(Z)
library(e1071)
fit_SVMR <-  svm(formula = Group ~ .,
data = x_train,
type = 'C-classification',
kernel = 'linear')
rm(list=c("adhd0", "adhd1", "adhd2", "adhd3"))
#training and testing data
## % 80 of the sample size
smp_size <- floor(0.8 * nrow(Z))
set.seed(2794)
train_ind <- sample(seq_len(nrow(Z)), size = smp_size)
x_train <- Z[train_ind, ]
y_train <- x_train[, 1]
x_test <- Z[-train_ind, ]
y_test <- x_test[ ,1]
library(e1071)
fit_SVMR <-  svm(formula = Group ~ .,
data = x_train,
type = 'C-classification',
kernel = 'linear')
#predicting the test set results
y_pred <- predict(fit_SVMR, newdata = x_test)
View(y_pred)
library(e1071)
fit_SVMR <-  svm(formula = Group ~ .,
data = x_train,
type = 'C-classification',
kernel = 'linear')
#predicting the test set results
y_pred <- predict(fit_SVMR, newdata = x_test[,-1])
View(y_pred)
y_pred
# Making the Confusion Matrix
cm_l = table(y_test, y_pred)
cm_l
error_SVML <- mean(y_pred=!y_test)
?`mean,Matrix-method`
?mean
error_SVML <- mean( y_pred !=y_test)
error_SVML
library(glmnet)
#train dataset
DATA <-  read.csv("train_data.csv")
adhd0 <- t(DATA)
adhd1 <- adhd0[-1, ]
#naming the colnames
colnames(adhd1) <- as.character(adhd1[1, ])
X <- apply(adhd1[,-1],2, as.numeric)
X <- data.frame(adhd1[ ,1],X)
adhd2 <- X[-1, ]
adhd3 <- as.matrix(adhd2)
colnames(adhd3)[1] <- "GROUP"
#defining control group=0
cat_v <- c()
for (i in 1:dim(adhd3)[1]){
if(adhd3[ ,"GROUP"][i] == "Controls")
{
cat_v[i]<-"0"
}else{
cat_v[i]<-"1"
}
}
adhd3 <- data.frame(cat_v, adhd3)
Z <- adhd3[ ,-2]
Z <- apply(Z,2,as.numeric)
colnames(Z)[1] <- "Group"
r <- Z[ ,1]
r <- as.vector(r)
adhd <- Z[ ,-1]
rm(list=c("adhd0", "adhd1", "adhd2", "adhd3"))
#training and testing data
## % 80 of the sample size
smp_size <- floor(0.8 * nrow(Z))
set.seed(2794)
train_ind <- sample(seq_len(nrow(Z)), size = smp_size)
x_train <- Z[train_ind, ]
y_train <- x_train[, 1]
x_test <- Z[-train_ind, ]
y_test <- x_test[ ,1]
setwd("C:/Users/pnuka/OneDrive/Documents/Fall 2022/Research- Stat/ADHD-SVM")
```{r}
library(glmnet)
#train dataset
DATA <-  read.csv("train_data.csv")
adhd0 <- t(DATA)
adhd1 <- adhd0[-1, ]
#naming the colnames
colnames(adhd1) <- as.character(adhd1[1, ])
X <- apply(adhd1[,-1],2, as.numeric)
X <- data.frame(adhd1[ ,1],X)
adhd2 <- X[-1, ]
adhd3 <- as.matrix(adhd2)
colnames(adhd3)[1] <- "GROUP"
#defining control group=0
cat_v <- c()
for (i in 1:dim(adhd3)[1]){
if(adhd3[ ,"GROUP"][i] == "Controls")
{
cat_v[i]<-"0"
}else{
cat_v[i]<-"1"
}
}
adhd3 <- data.frame(cat_v, adhd3)
Z <- adhd3[ ,-2]
Z <- apply(Z,2,as.numeric)
colnames(Z)[1] <- "Group"
rm(list=c("adhd0", "adhd1", "adhd2", "adhd3"))
#training and testing data
## % 80 of the sample size
smp_size <- floor(0.8 * nrow(Z))
set.seed(2794)
train_ind <- sample(seq_len(nrow(Z)), size = smp_size)
x_train <- Z[train_ind, ]
y_train <- x_train[, 1]
x_test <- Z[-train_ind, ]
y_test <- x_test[ ,1]
library(glmnet)
#train dataset
DATA <-  read.csv("train_data.csv")
adhd0 <- t(DATA)
adhd1 <- adhd0[-1, ]
#naming the colnames
colnames(adhd1) <- as.character(adhd1[1, ])
X <- apply(adhd1[,-1],2, as.numeric)
X <- data.frame(adhd1[ ,1],X)
adhd2 <- X[-1, ]
adhd3 <- as.matrix(adhd2)
colnames(adhd3)[1] <- "GROUP"
#defining control group=0
cat_v <- c()
for (i in 1:dim(adhd3)[1]){
if(adhd3[ ,"GROUP"][i] == "Controls")
{
cat_v[i]<-"0"
}else{
cat_v[i]<-"1"
}
}
adhd3 <- data.frame(cat_v, adhd3)
Z <- adhd3[ ,-2]
Z <- apply(Z,2,as.numeric)
colnames(Z)[1] <- "Group"
rm(list=c("adhd0", "adhd1", "adhd2", "adhd3"))
#training and testing data
## % 80 of the sample size
smp_size <- floor(0.8 * nrow(Z))
set.seed(2794)
train_ind <- sample(seq_len(nrow(Z)), size = smp_size)
x_train <- Z[train_ind, ]
y_train <- x_train[, 1]
x_test <- Z[-train_ind, ]
y_test <- x_test[ ,1]
#test dataset
DATA1 <-  read.csv("test_data.csv")
ADHD0 <- t(DATA1)
ADHD1 <- ADHD0[-1, ]
#naming the colnames
colnames(ADHD1) <- as.character(ADHD1[1, ])
X_t <- apply(ADHD1[,-1],2, as.numeric)
X_t <- data.frame(ADHD1[ ,1],X_t)
ADHD2 <- X_t[-1, ]
ADHD3 <- as.matrix(ADHD2)
colnames(ADHD3)[1] <- "group"
#defining control group=0
cat_t <- c()
for (i in 1:dim(ADHD3)[1]){
if(ADHD3[ ,"group"][i] == "Controls")
{
cat_t[i]<-"0"
}else{
cat_t[i]<-"1"
}
}
ADHD3 <- data.frame(cat_t, ADHD3)
Y<- ADHD3[ ,-2]
Y <- apply(Y,2,as.numeric)
colnames(Y)[1] <- "Group_t"
rm(list=c("ADHD0", "ADHD1", "ADHD2", "ADHD3"))
View(Y)
cv.model <- cv.glmnet(x=x_train, y=y_train, family= "binomial", alpha=1 )
plot(cv.model)
l.min <- cv.model$lambda.min
lasso_logistic.model <- glmnet(x_train, y_train, "binomial", alpha=1, lambda = l.min)
B <- lasso_logistic.model$beta
nnzero(B, na.counted = NA)
nnzero_indices <- which(B != 0, arr.ind = T)
nnzero_indices
train.model <- assess.glmnet(lasso_logistic.model, x_train, y_train)
train.model
test.model_split <- assess.glmnet(lasso_logistic.model, x_test, y_test)
test.model_split
test.model <- assess.glmnet(lasso_logistic.model, Y[,-1], Y[,1])
dim(Y)
dim(x_test)
dim(y_test)
cv.model <- cv.glmnet(x=x_train, y=y_train, family= "binomial", alpha=1 )
plot(cv.model)
l.min <- cv.model$lambda.min
lasso_logistic.model <- glmnet(x_train, y_train, "binomial", alpha=1, lambda = l.min)
B <- lasso_logistic.model$beta
nnzero(B, na.counted = NA)
nnzero_indices <- which(B != 0, arr.ind = T)
nnzero_indices
train.model <- assess.glmnet(lasso_logistic.model, x_train, y_train)
train.model
test.model_split <- assess.glmnet(lasso_logistic.model, x_test, y_test)
test.model_split
test.model <- assess.glmnet(lasso_logistic.model, Y[ ,-1], Y[ ,1])
View(Y[ ,-1])
cv.model <- cv.glmnet(x=x_train, y=y_train, family= "binomial", alpha=1 )
plot(cv.model)
l.min <- cv.model$lambda.min
lasso_logistic.model <- glmnet(x_train, y_train, "binomial", alpha=1, lambda = l.min)
B <- lasso_logistic.model$beta
nnzero(B, na.counted = NA)
nnzero_indices <- which(B != 0, arr.ind = T)
nnzero_indices
train.model <- assess.glmnet(lasso_logistic.model, x_train, y_train)
train.model
test.model_split <- assess.glmnet(lasso_logistic.model, x_test, y_test)
test.model_split
test.model <- assess.glmnet(lasso_logistic.model, Y, Y[ ,1])
test.model
cv.model <- cv.glmnet(x=x_train, y=y_train, family= "binomial", alpha=1 )
plot(cv.model)
l.min <- cv.model$lambda.min
lasso_logistic.model <- glmnet(x_train, y_train, "binomial", alpha=1, lambda = l.min)
B <- lasso_logistic.model$beta
nnzero(B, na.counted = NA)
nnzero_indices <- which(B != 0, arr.ind = T)
nnzero_indices
train.model <- assess.glmnet(lasso_logistic.model, x_train, y_train)
train.model$mse
test.model_split <- assess.glmnet(lasso_logistic.model, x_test, y_test)
test.model_split$mse
test.model <- assess.glmnet(lasso_logistic.model, Y, Y[ ,1])
test.model$mse
library(e1071)
fit_SVML <-  svm(formula = Group ~ .,
data = x_train,
type = 'C-classification',
kernel = 'linear')
#predicting the test set results for the split test data
ypred_split_SVML <- predict(fit_SVML, newdata = x_test[,-1])
# Making the Confusion Matrix for the split test data
CM_split_L = table(y_test, ypred_split_SVML)
error_split_SVML <- mean( ypred_split_SVML !=y_test)
error_split_SVML
#predicting the test set results for the original test data
ypred_SVML <- predict(fit_SVML, newdata = Y[,-1])
# Making the Confusion Matrix for the original test data
CM_L = table(Y[ ,1], ypred_SVML)
error_SVML <- mean( ypred_SVML != Y[ ,1])
error_SVML
fit_SVMR <-  svm(formula = Group ~ .,
data = x_train,
type = 'C-classification',
kernel = 'radial')
#predicting the test set results for the split test data
ypred_split_SVMR <- predict(fit_SVMR, newdata = x_test[,-1])
# Making the Confusion Matrix for the split test data
CM_split_R = table(y_test, ypred_split_SVMR)
error_split_SVMR <- mean( ypred_split_SVMR !=y_test)
error_split_SVMR
#predicting the test set results for the original test data
ypred_SVMR <- predict(fit_SVMR, newdata = Y[,-1])
# Making the Confusion Matrix for the original test data
CM_R = table(Y[ ,1], ypred_SVMR)
error_SVMR <- mean( ypred_SVMR != Y[ ,1])
error_SVMR
setwd("C:/Users/pnuka/OneDrive/Documents/Fall 2022/Research- Stat/GitHub/ADHD")
knitr::opts_chunk$set(echo = TRUE)
DATA <-  read.csv("train_data.csv")
adhd0 <- t(DATA)
adhd1 <- adhd0[-1, ]
#naming the colnames
colnames(adhd1) <- as.character(adhd1[1, ])
X <- apply(adhd1[,-1],2, as.numeric)
X <- data.frame(adhd1[ ,1],X)
adhd2 <- X[-1, ]
adhd3 <- as.matrix(adhd2)
colnames(adhd3)[1] <- "GROUP"
#defining control group=0
cat_v <- c()
for (i in 1:dim(adhd3)[1]){
if(adhd3[ ,"GROUP"][i] == "Controls")
{
cat_v[i]<-"0"
}else{
cat_v[i]<-"1"
}
}
#as.factor(cat_v)
adhd3 <- data.frame(cat_v, adhd3)
Z <- adhd3[ ,-2]
Z <- apply(Z,2,as.numeric)
r <- Z[ ,1]
r <- as.matrix(r)
adhd <- Z[ ,-1]
rm(list=c("adhd0", "adhd1", "adhd2", "adhd3", "Z"))
#training and testing data
## % 80 of the sample size
ind <- floor(0.8 * nrow(adhd))
set.seed(2705)
train_ind <- sample(seq_len(nrow(adhd)), size = ind)
x_train <- as.data.frame(adhd[train_ind, ])
y_train <- as.factor(r[train_ind, ])
x_test <- as.data.frame(adhd[-train_ind, ])
y_test <- as.factor(r[-train_ind, ])
#test dataset
DATA1 <-  read.csv("test_data.csv")
setwd("C:/Users/yagmu/Desktop/ADHD")
#test dataset
DATA1 <-  read.csv("test_data.csv")
#test dataset
DATA1 <-  read.csv("test_data.csv")
ADHD0 <- t(DATA1)
ADHD1 <- ADHD0[-1, ]
#naming the colnames
colnames(ADHD1) <- as.character(ADHD1[1, ])
X_t <- apply(ADHD1[,-1],2, as.numeric)
X_t <- data.frame(ADHD1[ ,1],X_t)
ADHD2 <- X_t[-1, ]
ADHD3 <- as.matrix(ADHD2)
colnames(ADHD3)[1] <- "group"
#defining control group=0
cat_t <- c()
for (i in 1:dim(ADHD3)[1]){
if(ADHD3[ ,"group"][i] == "Controls")
{
cat_t[i]<-"0"
}else{
cat_t[i]<-"1"
}
}
ADHD3 <- data.frame(cat_t, ADHD3)
Y<- ADHD3[ ,-2]
Y <- apply(Y,2,as.numeric)
colnames(Y)[1] <- "Group_t"
rm(list=c("ADHD0", "ADHD1", "ADHD2", "ADHD3"))
load("ADHD_package.Rda")
min_error = min(train_swag_svml$cv_alpha)
varmat_ind = list() #saves the varmat index from CV errors
for(i in 1:20){
varmat_ind[[i]]=which(train_swag_svml$CVs[[i]]<=min_error, arr.ind = T)
}
post_sel = list() # models selected after post-processing
for(i in 1:20){
post_sel[[i]] = train_swag_svml$VarMat[[i]][,varmat_ind[[i]]]
}
post_sel[[1]] = t(as.matrix(post_sel[[1]]))
for(i in 1:20){
if(!is.matrix(post_sel[[i]])){
post_sel[[i]]=t(as.matrix(post_sel[[i]]))
}
}
post_sel[[9]] = t(post_sel[[9]])
x = c() #non-empty elements of post-group
for(i in 1:20){
if(length(post_sel[[i]])!=0){
x = c(x,i)
}
x = x
}
for(i in 1:length(x)){
if(nrow(post_sel[[x[i]]])<20){
diff = 20 - nrow(post_sel[[x[i]]])
post_sel[[x[i]]] = rbind(post_sel[[x[i]]],matrix(NA,nrow = diff, ncol = ncol(post_sel[[x[i]]])))
}
}
models = matrix(NA, nrow = 20,ncol=ncol(post_sel[[x[1]]]))
models[1:nrow(post_sel[[x[1]]]),]=post_sel[[x[1]]]
for(i in 2:length(x)){
models = cbind(models,post_sel[[x[i]]])
}
models = t(models)
selected_var = c()
for(i in 1:ncol(models)){
selected_var = c(selected_var,models[,i])
}
selected_var = na.omit(unique(selected_var))
selected_var = sort(selected_var)
#colnames(x_train)[selected_var]
#table(models)
freq = table(models)
variable = colnames(x_train)[selected_var]
freq_table = cbind(variable,freq)
rownames(freq_table) = c(1:nrow(freq_table))
freq_table = as.data.frame(freq_table)
freq_table$freq = as.numeric(freq_table$freq)
freq_table
require(plotrix)
m_vector <- sapply(train_swag_svml$CVs, function(x) summary(x)[4])
l_vector <- sapply(train_swag_svml$CVs, function(x) summary(x)[1])
u_vector <- sapply(train_swag_svml$CVs, function(x) summary(x)[6])
plotCI(1:length(train_swag_svml$CVs), m_vector, ui=u_vector, li=l_vector, scol = "grey", col="red", pch = 16, main = "Ranges 10-fold CV Misclassification Errors",ylab = "Range CV Error",xlab = "Model Size")
load("SVMLinear_Results.Rda")
View(freq_table)
