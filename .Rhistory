knitr::opts_chunk$set(echo = FALSE)
## Loading the train dataset
DATA <-  read.csv("train_data.csv")
adhd0 <- t(DATA)
adhd1 <- adhd0[-1, ]
#naming the colnames
colnames(adhd1) <- as.character(adhd1[1, ])
X <- apply(adhd1[,-1],2, as.numeric)
X <- data.frame(adhd1[ ,1],X)
adhd2 <- X[-1, ]
adhd3 <- as.matrix(adhd2)
colnames(adhd3)[1] <- "GROUP"
#defining control group=0
cat_v <- c()
for (i in 1:dim(adhd3)[1]){
if(adhd3[ ,"GROUP"][i] == "Controls")
{
cat_v[i]<-"0"
}else{
cat_v[i]<-"1"
}
}
#as.factor(cat_v)
adhd3 <- data.frame(cat_v, adhd3)
Z <- adhd3[ ,-2]
Z <- apply(Z,2,as.numeric)
r <- Z[ ,1]
r <- as.matrix(r)
adhd <- Z[ ,-1]
rm(list=c("adhd0", "adhd1", "adhd2", "adhd3", "Z"))
## Splitting the training dataset
#training and testing data
## % 80 of the sample size
ind <- floor(0.8 * nrow(adhd))
set.seed(2705)
train_ind <- sample(seq_len(nrow(adhd)), size = ind)
x_train <- as.data.frame(adhd[train_ind, ])
y_train <- as.factor(r[train_ind, ])
x_test <- as.data.frame(adhd[-train_ind, ])
y_test <- as.factor(r[-train_ind, ])
dim(x_train)
dim(x_train[ ,1]= 0)
View(x_train)
knitr::opts_chunk$set(echo = FALSE)
## Loading the train dataset
DATA <-  read.csv("train_data.csv")
adhd0 <- t(DATA)
adhd1 <- adhd0[-1, ]
#naming the colnames
colnames(adhd1) <- as.character(adhd1[1, ])
X <- apply(adhd1[,-1],2, as.numeric)
X <- data.frame(adhd1[ ,1],X)
adhd2 <- X[-1, ]
adhd3 <- as.matrix(adhd2)
colnames(adhd3)[1] <- "GROUP"
#defining control group=0
cat_v <- c()
for (i in 1:dim(adhd3)[1]){
if(adhd3[ ,"GROUP"][i] == "Controls")
{
cat_v[i]<-"0"
}else{
cat_v[i]<-"1"
}
}
#as.factor(cat_v)
adhd3 <- data.frame(cat_v, adhd3)
Z <- adhd3[ ,-2]
Z <- apply(Z,2,as.numeric)
r <- Z[ ,1]
r <- as.matrix(r)
adhd <- Z[ ,-1]
rm(list=c("adhd0", "adhd1", "adhd2", "adhd3", "Z"))
## Splitting the training dataset
#training and testing data
## % 80 of the sample size
ind <- floor(0.8 * nrow(adhd))
set.seed(2705)
train_ind <- sample(seq_len(nrow(adhd)), size = ind)
x_train <- as.data.frame(adhd[train_ind, ])
y_train <- as.factor(r[train_ind, ])
x_test <- as.data.frame(adhd[-train_ind, ])
y_test <- as.factor(r[-train_ind, ])
dim(y_train)
as.matrix(y_train)
length(y_train== 0)
length(which(y_train== 0))
dim(x_train)
setwd("C:/Users/pnuka/OneDrive/Documents/Fall 2022/Research- Stat/GitHub/ADHD")
setwd("C:/Users/pnuka/OneDrive/Documents/Fall 2022/Research- Stat/GitHub/ADHD")
knitr::opts_chunk$set(echo = FALSE)
## Loading the train dataset
DATA <-  read.csv("train_data.csv")
adhd0 <- t(DATA)
adhd1 <- adhd0[-1, ]
#naming the colnames
colnames(adhd1) <- as.character(adhd1[1, ])
X <- apply(adhd1[,-1],2, as.numeric)
X <- data.frame(adhd1[ ,1],X)
adhd2 <- X[-1, ]
adhd3 <- as.matrix(adhd2)
colnames(adhd3)[1] <- "GROUP"
#defining control group=0
cat_v <- c()
for (i in 1:dim(adhd3)[1]){
if(adhd3[ ,"GROUP"][i] == "Controls")
{
cat_v[i]<-"0"
}else{
cat_v[i]<-"1"
}
}
#as.factor(cat_v)
adhd3 <- data.frame(cat_v, adhd3)
Z <- adhd3[ ,-2]
Z <- apply(Z,2,as.numeric)
r <- Z[ ,1]
r <- as.matrix(r)
adhd <- Z[ ,-1]
rm(list=c("adhd0", "adhd1", "adhd2", "adhd3", "Z"))
## Splitting the training dataset
#training and testing data
## % 80 of the sample size
ind <- floor(0.8 * nrow(adhd))
set.seed(2705)
train_ind <- sample(seq_len(nrow(adhd)), size = ind)
x_train <- as.data.frame(adhd[train_ind, ])
y_train <- as.factor(r[train_ind, ])
x_test <- as.data.frame(adhd[-train_ind, ])
y_test <- as.factor(r[-train_ind, ])
## Loading the SWAG Logistic Regression results
load("Logistic_Regression_Results.Rda")
## Post-processing
min_error = min(train_swag_svml$cv_alpha)
varmat_ind = list() #saves the varmat index from CV errors
for(i in 1:20){
varmat_ind[[i]]=which(train_swag_svml$CVs[[i]]<=min_error, arr.ind = T)
}
post_sel = list() # models selected after post-processing
for(i in 1:20){
post_sel[[i]] = train_swag_svml$VarMat[[i]][,varmat_ind[[i]]]
}
post_sel[[1]] = t(as.matrix(post_sel[[1]]))
for(i in 1:20){
if(!is.matrix(post_sel[[i]])){
post_sel[[i]]=t(as.matrix(post_sel[[i]]))
}
}
post_sel[[9]] = t(post_sel[[9]])
x = c() #non-empty elements of post-group
for(i in 1:20){
if(length(post_sel[[i]])!=0){
x = c(x,i)
}
x = x
}
for(i in 1:length(x)){
if(nrow(post_sel[[x[i]]])<20){
diff = 20 - nrow(post_sel[[x[i]]])
post_sel[[x[i]]] = rbind(post_sel[[x[i]]],matrix(NA,nrow = diff, ncol = ncol(post_sel[[x[i]]])))
}
}
models = matrix(NA, nrow = 20,ncol=ncol(post_sel[[x[1]]]))
models[1:nrow(post_sel[[x[1]]]),]=post_sel[[x[1]]]
for(i in 2:length(x)){
models = cbind(models,post_sel[[x[i]]])
}
models = t(models)
selected_var = c()
for(i in 1:ncol(models)){
selected_var = c(selected_var,models[,i])
}
selected_var = na.omit(unique(selected_var))
selected_var = sort(selected_var)
#colnames(x_train)[selected_var]
#table(models)
freq = table(models)
variable = colnames(x_train)[selected_var]
freq_table = cbind(variable,freq)
rownames(freq_table) = c(1:nrow(freq_table))
freq_table = as.data.frame(freq_table)
freq_table$freq = as.numeric(freq_table$freq)
#freq_table
typeof(freq_table)
as.data.frame(freq_table)
install.packages("writexl")
library("writexl")
library("writexl")
library("writexl")
## Post-processing
min_error = min(train_swag_svml$cv_alpha)
varmat_ind = list() #saves the varmat index from CV errors
for(i in 1:20){
varmat_ind[[i]]=which(train_swag_svml$CVs[[i]]<=min_error, arr.ind = T)
}
post_sel = list() # models selected after post-processing
for(i in 1:20){
post_sel[[i]] = train_swag_svml$VarMat[[i]][,varmat_ind[[i]]]
}
post_sel[[1]] = t(as.matrix(post_sel[[1]]))
for(i in 1:20){
if(!is.matrix(post_sel[[i]])){
post_sel[[i]]=t(as.matrix(post_sel[[i]]))
}
}
post_sel[[9]] = t(post_sel[[9]])
x = c() #non-empty elements of post-group
for(i in 1:20){
if(length(post_sel[[i]])!=0){
x = c(x,i)
}
x = x
}
for(i in 1:length(x)){
if(nrow(post_sel[[x[i]]])<20){
diff = 20 - nrow(post_sel[[x[i]]])
post_sel[[x[i]]] = rbind(post_sel[[x[i]]],matrix(NA,nrow = diff, ncol = ncol(post_sel[[x[i]]])))
}
}
models = matrix(NA, nrow = 20,ncol=ncol(post_sel[[x[1]]]))
models[1:nrow(post_sel[[x[1]]]),]=post_sel[[x[1]]]
for(i in 2:length(x)){
models = cbind(models,post_sel[[x[i]]])
}
models = t(models)
selected_var = c()
for(i in 1:ncol(models)){
selected_var = c(selected_var,models[,i])
}
selected_var = na.omit(unique(selected_var))
selected_var = sort(selected_var)
#colnames(x_train)[selected_var]
#table(models)
freq = table(models)
variable = colnames(x_train)[selected_var]
freq_table = cbind(variable,freq)
rownames(freq_table) = c(1:nrow(freq_table))
freq_table = as.data.frame(freq_table)
freq_table$freq = as.numeric(freq_table$freq)
as.data.frame(freq_table)
#freq_table
as.data.frame(freq_table)
?write_xlsx
write_xlsx(freq_table,"C:\\Users\\pnuka\\OneDrive\\Documents\\Fall 2022\\Research- Stat\\GitHub\\LogisticFT.xlsx")
adhd = read.csv("train_data.csv")
adhd = as.data.frame(t(adhd))
#str(adhd)
colnames(adhd) = as.character(adhd[2,])
adhd = adhd[-(1:2),]
X = apply(adhd[,-1], 2, as.numeric)
adhd = data.frame(adhd[,1], X)
adhd = as.data.frame(adhd)
rownames(adhd) = 1:nrow(adhd)
adhd[adhd == "Controls"]=0
adhd[adhd == "ADHD-C" | adhd == "ADHD-H" | adhd == "ADHD-I"]=1
predictors = as.data.frame(adhd[,-1])
y = as.factor(adhd[,1])
set.seed(2705)
ind = sample(1:dim(predictors)[1],dim(predictors)[1]*0.2)
y_test = y[ind]
y_train = y[-ind]
x_test = predictors[ind,]
x_train = predictors[-ind,]
load("SVM_Radial_Results.Rda")
library("writexl")
min_error = min(train_swag_svmradial$cv_alpha)
varmat_ind = list() #saves the varmat index from CV errors
for(i in 1:20){
varmat_ind[[i]]=which(train_swag_svmradial$CVs[[i]]<=min_error, arr.ind = T)
}
post_sel = list() # models selected after post-processing
for(i in 1:20){
post_sel[[i]] = train_swag_svmradial$VarMat[[i]][,varmat_ind[[i]]]
}
post_sel[[1]] = t(as.matrix(post_sel[[1]]))
for(i in 1:20){
if(!is.matrix(post_sel[[i]])){
post_sel[[i]]=t(as.matrix(post_sel[[i]]))
}
}
x = c() #non-empty elements of post-group
for(i in 1:20){
if(length(post_sel[[i]])!=0){
x = c(x,i)
}
x = x
}
for(i in 1:length(x)){
if(nrow(post_sel[[x[i]]])<20){
diff = 20 - nrow(post_sel[[x[i]]])
post_sel[[x[i]]] = rbind(post_sel[[x[i]]],matrix(NA,nrow = diff, ncol = ncol(post_sel[[x[i]]])))
}
}
models = matrix(NA, nrow = 20,ncol=ncol(post_sel[[x[1]]]))
models[1:nrow(post_sel[[x[1]]]),]=post_sel[[x[1]]]
for(i in 2:length(x)){
models = cbind(models,post_sel[[x[i]]])
}
models = t(models)
selected_var = c()
for(i in 1:ncol(models)){
selected_var = c(selected_var,models[,i])
}
selected_var = na.omit(unique(selected_var))
selected_var = sort(selected_var)
freq = table(models)
variable = colnames(x_train)[selected_var]
freq_table = cbind(variable,freq)
rownames(freq_table) = c(1:nrow(freq_table))
freq_table = as.data.frame(freq_table)
freq_table$freq = as.numeric(freq_table$freq)
as.data.frame(freq_table)
write_xlsx(freq_table,"C:\\Users\\pnuka\\OneDrive\\Documents\\Fall 2022\\Research- Stat\\GitHub\\SVMRadialFT.xlsx")
#freq_table
require(plotrix)
m_vector <- sapply(train_swag_svmradial$CVs, function(x) summary(x)[4])
l_vector <- sapply(train_swag_svmradial$CVs, function(x) summary(x)[1])
u_vector <- sapply(train_swag_svmradial$CVs, function(x) summary(x)[6])
plotCI(1:length(train_swag_svmradial$CVs), m_vector, ui=u_vector, li=l_vector,
scol = "grey", col="red", pch = 16, main = "Ranges 10-fold CV Misclassification Errors",
ylab = "Range CV Error",xlab = "Model Size")
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
DATA <-  read.csv("train_data.csv")
adhd0 <- t(DATA)
adhd1 <- adhd0[-1, ]
#naming the colnames
colnames(adhd1) <- as.character(adhd1[1, ])
X <- apply(adhd1[,-1],2, as.numeric)
X <- data.frame(adhd1[ ,1],X)
adhd2 <- X[-1, ]
adhd3 <- as.matrix(adhd2)
colnames(adhd3)[1] <- "GROUP"
#defining control group=0
cat_v <- c()
for (i in 1:dim(adhd3)[1]){
if(adhd3[ ,"GROUP"][i] == "Controls")
{
cat_v[i]<-"0"
}else{
cat_v[i]<-"1"
}
}
#as.factor(cat_v)
adhd3 <- data.frame(cat_v, adhd3)
Z <- adhd3[ ,-2]
Z <- apply(Z,2,as.numeric)
r <- Z[ ,1]
r <- as.matrix(r)
adhd <- Z[ ,-1]
rm(list=c("adhd0", "adhd1", "adhd2", "adhd3", "Z"))
#training and testing data
## % 80 of the sample size
ind <- floor(0.8 * nrow(adhd))
set.seed(2705)
train_ind <- sample(seq_len(nrow(adhd)), size = ind)
x_train <- as.data.frame(adhd[train_ind, ])
y_train <- as.factor(r[train_ind, ])
x_test <- as.data.frame(adhd[-train_ind, ])
y_test <- as.factor(r[-train_ind, ])
## Loading the SWAG SVM Linear results
load("SVMLinear_Results.Rda")
## Loading the SWAG SVM Linear results
load("SVM_Linear_Results.Rda")
## Post-processing
library("writexl")
min_error = min(train_swag_svml$cv_alpha)
varmat_ind = list() #saves the varmat index from CV errors
for(i in 1:20){
varmat_ind[[i]]=which(train_swag_svml$CVs[[i]]<=min_error, arr.ind = T)
}
post_sel = list() # models selected after post-processing
for(i in 1:20){
post_sel[[i]] = train_swag_svml$VarMat[[i]][,varmat_ind[[i]]]
}
post_sel[[1]] = t(as.matrix(post_sel[[1]]))
for(i in 1:20){
if(!is.matrix(post_sel[[i]])){
post_sel[[i]]=t(as.matrix(post_sel[[i]]))
}
}
post_sel[[9]] = t(post_sel[[9]])
x = c() #non-empty elements of post-group
for(i in 1:20){
if(length(post_sel[[i]])!=0){
x = c(x,i)
}
x = x
}
for(i in 1:length(x)){
if(nrow(post_sel[[x[i]]])<20){
diff = 20 - nrow(post_sel[[x[i]]])
post_sel[[x[i]]] = rbind(post_sel[[x[i]]],matrix(NA,nrow = diff, ncol = ncol(post_sel[[x[i]]])))
}
}
models = matrix(NA, nrow = 20,ncol=ncol(post_sel[[x[1]]]))
models[1:nrow(post_sel[[x[1]]]),]=post_sel[[x[1]]]
for(i in 2:length(x)){
models = cbind(models,post_sel[[x[i]]])
}
models = t(models)
selected_var = c()
for(i in 1:ncol(models)){
selected_var = c(selected_var,models[,i])
}
selected_var = na.omit(unique(selected_var))
selected_var = sort(selected_var)
#colnames(x_train)[selected_var]
#table(models)
freq = table(models)
variable = colnames(x_train)[selected_var]
freq_table = cbind(variable,freq)
rownames(freq_table) = c(1:nrow(freq_table))
freq_table = as.data.frame(freq_table)
freq_table$freq = as.numeric(freq_table$freq)
as.data.frame(freq_table)
write_xlsx(freq_table,"C:\\Users\\pnuka\\OneDrive\\Documents\\Fall 2022\\Research- Stat\\GitHub\\SVMLinearFT.xlsx")
#freq_table
