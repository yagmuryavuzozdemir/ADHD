U3
# bootstrap estimates of the LS age coefficient 95% CI
lb_bootLSage <- quantile(bh[ ,2] ,0.025)
ub_bootLSage <- quantile(bh[ ,2] ,0.975)
U4 <- matrix(c(lb_bootLSage,ub_bootLSage), ncol=2, dimnames = list(c("Age"),c("2.5%", "97.5%")) )
U4
# bootstrap estimates of the LS weight coefficient 95% CI
lb_bootLSweight <- quantile(bh[ ,3] ,0.025)
ub_bootLSweight <- quantile(bh[ ,3] ,0.975)
U5 <- matrix(c(lb_bootLSweight,ub_bootLSweight), ncol=2, dimnames = list(c("Weight"),c("2.5%", "97.5%")) )
U5
# bootstrap estimates of the LS skin coefficient 95% CI
lb_bootLSskin <- quantile(bh[ ,4] ,0.025)
ub_bootLSskin <- quantile(bh[ ,4] ,0.975)
U6 <- matrix(c(lb_bootLSskin,ub_bootLSskin), ncol=2, dimnames = list(c("Skin"),c("2.5%", "97.5%")) )
U6
# bootstrap estimates of the LAD intercept coefficient 95% CI
lb_bootLADintercept <- quantile(bt[ ,1] ,0.025)
ub_bootLADintercept <- quantile(bt[ ,1] ,0.975)
U7 <- matrix(c(lb_bootLADintercept,ub_bootLADintercept), ncol=2, dimnames = list(c("Intercept"),c("2.5%", "97.5%")) )
U7
# bootstrap estimates of the LAD age coefficient 95% CI
lb_bootLADage <- quantile(bt[ ,2] ,0.025)
ub_bootLADage <- quantile(bt[ ,2] ,0.975)
U8 <- matrix(c(lb_bootLADage,ub_bootLADage), ncol=2, dimnames = list(c("Age"),c("2.5%", "97.5%")) )
U8
# bootstrap estimates of the LAD weight coefficient 95% CI
lb_bootLADweight <- quantile(bt[ ,3] ,0.025)
ub_bootLADweight <- quantile(bt[ ,3] ,0.975)
U9 <- matrix(c(lb_bootLADweight,ub_bootLADweight), ncol=2, dimnames = list(c("Weight"),c("2.5%", "97.5%")) )
U9
# bootstrap estimates of the LAD skin coefficient 95% CI
lb_bootLADskin <- quantile(bt[ ,4] ,0.025)
ub_bootLADskin <- quantile(bt[ ,4] ,0.975)
U10 <- matrix(c(lb_bootLADskin,ub_bootLADskin), ncol=2, dimnames = list(c("Skin"),c("2.5%", "97.5%")) )
U10
knitr::opts_chunk$set(echo = FALSE)
A <- matrix(c(1, 0, 0, 1, -1, 0, 0, -1), ncol=4)
A
B <- A %*% t(A)
B
C <- t(A)%*% solve(B)
C
install.packages("glmnet")
library(glmnet)
DATA <-  read.csv("train_data.csv")
adhd0 <- t(DATA)
adhd1 <- adhd0[-1, ]
#naming the colnames
colnames(adhd1) <- as.character(adhd1[1, ])
X <- apply(adhd1[,-1],2, as.numeric)
X <- data.frame(adhd1[ ,1],X)
adhd2 <- X[-1, ]
adhd3 <- as.matrix(adhd2)
colnames(adhd3)[1] <- "GROUP"
#defining control group=0
cat_v <- c()
for (i in 1:dim(adhd3)[1]){
if(adhd3[ ,"GROUP"][i] == "Controls")
{
cat_v[i]<-"0"
}else{
cat_v[i]<-"1"
}
}
adhd3 <- data.frame(cat_v, adhd3)
Z <- adhd3[ ,-2]
Z <- apply(Z,2,as.numeric)
r <- Z[ ,1]
r <- as.vector(r)
adhd <- Z[ ,-1]
rm(list=c("adhd0", "adhd1", "adhd2", "adhd3"))
library(glmnet)
setwd("C:/Users/pnuka/OneDrive/Documents/Fall 2022/Research- Stat/ADHD-SVM")
DATA <-  read.csv("train_data.csv")
adhd0 <- t(DATA)
adhd1 <- adhd0[-1, ]
#naming the colnames
colnames(adhd1) <- as.character(adhd1[1, ])
X <- apply(adhd1[,-1],2, as.numeric)
X <- data.frame(adhd1[ ,1],X)
adhd2 <- X[-1, ]
adhd3 <- as.matrix(adhd2)
colnames(adhd3)[1] <- "GROUP"
#defining control group=0
cat_v <- c()
for (i in 1:dim(adhd3)[1]){
if(adhd3[ ,"GROUP"][i] == "Controls")
{
cat_v[i]<-"0"
}else{
cat_v[i]<-"1"
}
}
adhd3 <- data.frame(cat_v, adhd3)
Z <- adhd3[ ,-2]
Z <- apply(Z,2,as.numeric)
r <- Z[ ,1]
r <- as.vector(r)
adhd <- Z[ ,-1]
rm(list=c("adhd0", "adhd1", "adhd2", "adhd3"))
cv.model <- cv.glmnet(x=adhd, y=r, family= "binomial", alpha=1 )
plot(cv.model)
l.min <- cv.model$lambda.min
lasso_logistic.model <- glmnet(adhd, r, "binomial", alpha=1, lambda = l.min)
lasso_logistic.model$beta
summary(lasso_logistic.model)
B <- lasso_logistic.model$beta
View(B)
View(B)
lasso_logistic.model$beta
View(adhd)
rm(B)
library(glmnet)
DATA <-  read.csv("train_data.csv")
adhd0 <- t(DATA)
adhd1 <- adhd0[-1, ]
#naming the colnames
colnames(adhd1) <- as.character(adhd1[1, ])
X <- apply(adhd1[,-1],2, as.numeric)
X <- data.frame(adhd1[ ,1],X)
adhd2 <- X[-1, ]
adhd3 <- as.matrix(adhd2)
colnames(adhd3)[1] <- "GROUP"
#defining control group=0
cat_v <- c()
for (i in 1:dim(adhd3)[1]){
if(adhd3[ ,"GROUP"][i] == "Controls")
{
cat_v[i]<-"0"
}else{
cat_v[i]<-"1"
}
}
adhd3 <- data.frame(cat_v, adhd3)
Z <- adhd3[ ,-2]
Z <- apply(Z,2,as.numeric)
r <- Z[ ,1]
r <- as.vector(r)
adhd <- Z[ ,-1]
rm(list=c("adhd0", "adhd1", "adhd2", "adhd3"))
logitControl  <- trainControl(method="repeatedcv",number = 10,repeats = 1)
cv.model <- cv.glmnet(x=adhd, y=r, family= "binomial", alpha=1 )
plot(cv.model)
l.min <- cv.model$lambda.min
lasso_logistic.model <- glmnet(adhd, r, "binomial", alpha=1, lambda = l.min)
library(glmnet)
DATA <-  read.csv("train_data.csv")
adhd0 <- t(DATA)
adhd1 <- adhd0[-1, ]
#naming the colnames
colnames(adhd1) <- as.character(adhd1[1, ])
X <- apply(adhd1[,-1],2, as.numeric)
X <- data.frame(adhd1[ ,1],X)
adhd2 <- X[-1, ]
adhd3 <- as.matrix(adhd2)
colnames(adhd3)[1] <- "GROUP"
#defining control group=0
cat_v <- c()
for (i in 1:dim(adhd3)[1]){
if(adhd3[ ,"GROUP"][i] == "Controls")
{
cat_v[i]<-"0"
}else{
cat_v[i]<-"1"
}
}
adhd3 <- data.frame(cat_v, adhd3)
Z <- adhd3[ ,-2]
Z <- apply(Z,2,as.numeric)
r <- Z[ ,1]
r <- as.vector(r)
adhd <- Z[ ,-1]
rm(list=c("adhd0", "adhd1", "adhd2", "adhd3"))
# logitControl  <- trainControl(method="repeatedcv",number = 10,repeats = 1)
cv.model <- cv.glmnet(x=adhd, y=r, family= "binomial", alpha=1 )
plot(cv.model)
l.min <- cv.model$lambda.min
lasso_logistic.model <- glmnet(adhd, r, "binomial", alpha=1, lambda = l.min)
B <- lasso_logistic.model$beta
B <- lasso_logistic.model$beta
install.packages("Matrix")
install.packages("Matrix")
install.packages("Matrix")
install.packages("Matrix")
?predict
install.packages("e1071")
View(Z)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
library(glmnet)
DATA <-  read.csv("train_data.csv")
adhd0 <- t(DATA)
adhd1 <- adhd0[-1, ]
#naming the colnames
colnames(adhd1) <- as.character(adhd1[1, ])
X <- apply(adhd1[,-1],2, as.numeric)
X <- data.frame(adhd1[ ,1],X)
adhd2 <- X[-1, ]
adhd3 <- as.matrix(adhd2)
colnames(adhd3)[1] <- "GROUP"
#defining control group=0
cat_v <- c()
for (i in 1:dim(adhd3)[1]){
if(adhd3[ ,"GROUP"][i] == "Controls")
{
cat_v[i]<-"0"
}else{
cat_v[i]<-"1"
}
}
adhd3 <- data.frame(cat_v, adhd3)
Z <- adhd3[ ,-2]
Z <- apply(Z,2,as.numeric)
View(Z)
library(glmnet)
DATA <-  read.csv("train_data.csv")
adhd0 <- t(DATA)
adhd1 <- adhd0[-1, ]
#naming the colnames
colnames(adhd1) <- as.character(adhd1[1, ])
X <- apply(adhd1[,-1],2, as.numeric)
X <- data.frame(adhd1[ ,1],X)
adhd2 <- X[-1, ]
adhd3 <- as.matrix(adhd2)
colnames(adhd3)[1] <- "GROUP"
#defining control group=0
cat_v <- c()
for (i in 1:dim(adhd3)[1]){
if(adhd3[ ,"GROUP"][i] == "Controls")
{
cat_v[i]<-"0"
}else{
cat_v[i]<-"1"
}
}
adhd3 <- data.frame(cat_v, adhd3)
Z <- adhd3[ ,-2]
Z <- apply(Z,2,as.numeric)
colnames(Z)[1] <- "Group"
View(Z)
library(e1071)
fit_SVMR <-  svm(formula = Group ~ .,
data = x_train,
type = 'C-classification',
kernel = 'linear')
rm(list=c("adhd0", "adhd1", "adhd2", "adhd3"))
#training and testing data
## % 80 of the sample size
smp_size <- floor(0.8 * nrow(Z))
set.seed(2794)
train_ind <- sample(seq_len(nrow(Z)), size = smp_size)
x_train <- Z[train_ind, ]
y_train <- x_train[, 1]
x_test <- Z[-train_ind, ]
y_test <- x_test[ ,1]
library(e1071)
fit_SVMR <-  svm(formula = Group ~ .,
data = x_train,
type = 'C-classification',
kernel = 'linear')
#predicting the test set results
y_pred <- predict(fit_SVMR, newdata = x_test)
View(y_pred)
library(e1071)
fit_SVMR <-  svm(formula = Group ~ .,
data = x_train,
type = 'C-classification',
kernel = 'linear')
#predicting the test set results
y_pred <- predict(fit_SVMR, newdata = x_test[,-1])
View(y_pred)
y_pred
# Making the Confusion Matrix
cm_l = table(y_test, y_pred)
cm_l
error_SVML <- mean(y_pred=!y_test)
?`mean,Matrix-method`
?mean
error_SVML <- mean( y_pred !=y_test)
error_SVML
library(glmnet)
#train dataset
DATA <-  read.csv("train_data.csv")
adhd0 <- t(DATA)
adhd1 <- adhd0[-1, ]
#naming the colnames
colnames(adhd1) <- as.character(adhd1[1, ])
X <- apply(adhd1[,-1],2, as.numeric)
X <- data.frame(adhd1[ ,1],X)
adhd2 <- X[-1, ]
adhd3 <- as.matrix(adhd2)
colnames(adhd3)[1] <- "GROUP"
#defining control group=0
cat_v <- c()
for (i in 1:dim(adhd3)[1]){
if(adhd3[ ,"GROUP"][i] == "Controls")
{
cat_v[i]<-"0"
}else{
cat_v[i]<-"1"
}
}
adhd3 <- data.frame(cat_v, adhd3)
Z <- adhd3[ ,-2]
Z <- apply(Z,2,as.numeric)
colnames(Z)[1] <- "Group"
r <- Z[ ,1]
r <- as.vector(r)
adhd <- Z[ ,-1]
rm(list=c("adhd0", "adhd1", "adhd2", "adhd3"))
#training and testing data
## % 80 of the sample size
smp_size <- floor(0.8 * nrow(Z))
set.seed(2794)
train_ind <- sample(seq_len(nrow(Z)), size = smp_size)
x_train <- Z[train_ind, ]
y_train <- x_train[, 1]
x_test <- Z[-train_ind, ]
y_test <- x_test[ ,1]
setwd("C:/Users/pnuka/OneDrive/Documents/Fall 2022/Research- Stat/ADHD-SVM")
```{r}
library(glmnet)
#train dataset
DATA <-  read.csv("train_data.csv")
adhd0 <- t(DATA)
adhd1 <- adhd0[-1, ]
#naming the colnames
colnames(adhd1) <- as.character(adhd1[1, ])
X <- apply(adhd1[,-1],2, as.numeric)
X <- data.frame(adhd1[ ,1],X)
adhd2 <- X[-1, ]
adhd3 <- as.matrix(adhd2)
colnames(adhd3)[1] <- "GROUP"
#defining control group=0
cat_v <- c()
for (i in 1:dim(adhd3)[1]){
if(adhd3[ ,"GROUP"][i] == "Controls")
{
cat_v[i]<-"0"
}else{
cat_v[i]<-"1"
}
}
adhd3 <- data.frame(cat_v, adhd3)
Z <- adhd3[ ,-2]
Z <- apply(Z,2,as.numeric)
colnames(Z)[1] <- "Group"
rm(list=c("adhd0", "adhd1", "adhd2", "adhd3"))
#training and testing data
## % 80 of the sample size
smp_size <- floor(0.8 * nrow(Z))
set.seed(2794)
train_ind <- sample(seq_len(nrow(Z)), size = smp_size)
x_train <- Z[train_ind, ]
y_train <- x_train[, 1]
x_test <- Z[-train_ind, ]
y_test <- x_test[ ,1]
library(glmnet)
#train dataset
DATA <-  read.csv("train_data.csv")
adhd0 <- t(DATA)
adhd1 <- adhd0[-1, ]
#naming the colnames
colnames(adhd1) <- as.character(adhd1[1, ])
X <- apply(adhd1[,-1],2, as.numeric)
X <- data.frame(adhd1[ ,1],X)
adhd2 <- X[-1, ]
adhd3 <- as.matrix(adhd2)
colnames(adhd3)[1] <- "GROUP"
#defining control group=0
cat_v <- c()
for (i in 1:dim(adhd3)[1]){
if(adhd3[ ,"GROUP"][i] == "Controls")
{
cat_v[i]<-"0"
}else{
cat_v[i]<-"1"
}
}
adhd3 <- data.frame(cat_v, adhd3)
Z <- adhd3[ ,-2]
Z <- apply(Z,2,as.numeric)
colnames(Z)[1] <- "Group"
rm(list=c("adhd0", "adhd1", "adhd2", "adhd3"))
#training and testing data
## % 80 of the sample size
smp_size <- floor(0.8 * nrow(Z))
set.seed(2794)
train_ind <- sample(seq_len(nrow(Z)), size = smp_size)
x_train <- Z[train_ind, ]
y_train <- x_train[, 1]
x_test <- Z[-train_ind, ]
y_test <- x_test[ ,1]
#test dataset
DATA1 <-  read.csv("test_data.csv")
ADHD0 <- t(DATA1)
ADHD1 <- ADHD0[-1, ]
#naming the colnames
colnames(ADHD1) <- as.character(ADHD1[1, ])
X_t <- apply(ADHD1[,-1],2, as.numeric)
X_t <- data.frame(ADHD1[ ,1],X_t)
ADHD2 <- X_t[-1, ]
ADHD3 <- as.matrix(ADHD2)
colnames(ADHD3)[1] <- "group"
#defining control group=0
cat_t <- c()
for (i in 1:dim(ADHD3)[1]){
if(ADHD3[ ,"group"][i] == "Controls")
{
cat_t[i]<-"0"
}else{
cat_t[i]<-"1"
}
}
ADHD3 <- data.frame(cat_t, ADHD3)
Y<- ADHD3[ ,-2]
Y <- apply(Y,2,as.numeric)
colnames(Y)[1] <- "Group_t"
rm(list=c("ADHD0", "ADHD1", "ADHD2", "ADHD3"))
View(Y)
cv.model <- cv.glmnet(x=x_train, y=y_train, family= "binomial", alpha=1 )
plot(cv.model)
l.min <- cv.model$lambda.min
lasso_logistic.model <- glmnet(x_train, y_train, "binomial", alpha=1, lambda = l.min)
B <- lasso_logistic.model$beta
nnzero(B, na.counted = NA)
nnzero_indices <- which(B != 0, arr.ind = T)
nnzero_indices
train.model <- assess.glmnet(lasso_logistic.model, x_train, y_train)
train.model
test.model_split <- assess.glmnet(lasso_logistic.model, x_test, y_test)
test.model_split
test.model <- assess.glmnet(lasso_logistic.model, Y[,-1], Y[,1])
dim(Y)
dim(x_test)
dim(y_test)
cv.model <- cv.glmnet(x=x_train, y=y_train, family= "binomial", alpha=1 )
plot(cv.model)
l.min <- cv.model$lambda.min
lasso_logistic.model <- glmnet(x_train, y_train, "binomial", alpha=1, lambda = l.min)
B <- lasso_logistic.model$beta
nnzero(B, na.counted = NA)
nnzero_indices <- which(B != 0, arr.ind = T)
nnzero_indices
train.model <- assess.glmnet(lasso_logistic.model, x_train, y_train)
train.model
test.model_split <- assess.glmnet(lasso_logistic.model, x_test, y_test)
test.model_split
test.model <- assess.glmnet(lasso_logistic.model, Y[ ,-1], Y[ ,1])
View(Y[ ,-1])
cv.model <- cv.glmnet(x=x_train, y=y_train, family= "binomial", alpha=1 )
plot(cv.model)
l.min <- cv.model$lambda.min
lasso_logistic.model <- glmnet(x_train, y_train, "binomial", alpha=1, lambda = l.min)
B <- lasso_logistic.model$beta
nnzero(B, na.counted = NA)
nnzero_indices <- which(B != 0, arr.ind = T)
nnzero_indices
train.model <- assess.glmnet(lasso_logistic.model, x_train, y_train)
train.model
test.model_split <- assess.glmnet(lasso_logistic.model, x_test, y_test)
test.model_split
test.model <- assess.glmnet(lasso_logistic.model, Y, Y[ ,1])
test.model
cv.model <- cv.glmnet(x=x_train, y=y_train, family= "binomial", alpha=1 )
plot(cv.model)
l.min <- cv.model$lambda.min
lasso_logistic.model <- glmnet(x_train, y_train, "binomial", alpha=1, lambda = l.min)
B <- lasso_logistic.model$beta
nnzero(B, na.counted = NA)
nnzero_indices <- which(B != 0, arr.ind = T)
nnzero_indices
train.model <- assess.glmnet(lasso_logistic.model, x_train, y_train)
train.model$mse
test.model_split <- assess.glmnet(lasso_logistic.model, x_test, y_test)
test.model_split$mse
test.model <- assess.glmnet(lasso_logistic.model, Y, Y[ ,1])
test.model$mse
library(e1071)
fit_SVML <-  svm(formula = Group ~ .,
data = x_train,
type = 'C-classification',
kernel = 'linear')
#predicting the test set results for the split test data
ypred_split_SVML <- predict(fit_SVML, newdata = x_test[,-1])
# Making the Confusion Matrix for the split test data
CM_split_L = table(y_test, ypred_split_SVML)
error_split_SVML <- mean( ypred_split_SVML !=y_test)
error_split_SVML
#predicting the test set results for the original test data
ypred_SVML <- predict(fit_SVML, newdata = Y[,-1])
# Making the Confusion Matrix for the original test data
CM_L = table(Y[ ,1], ypred_SVML)
error_SVML <- mean( ypred_SVML != Y[ ,1])
error_SVML
fit_SVMR <-  svm(formula = Group ~ .,
data = x_train,
type = 'C-classification',
kernel = 'radial')
#predicting the test set results for the split test data
ypred_split_SVMR <- predict(fit_SVMR, newdata = x_test[,-1])
# Making the Confusion Matrix for the split test data
CM_split_R = table(y_test, ypred_split_SVMR)
error_split_SVMR <- mean( ypred_split_SVMR !=y_test)
error_split_SVMR
#predicting the test set results for the original test data
ypred_SVMR <- predict(fit_SVMR, newdata = Y[,-1])
# Making the Confusion Matrix for the original test data
CM_R = table(Y[ ,1], ypred_SVMR)
error_SVMR <- mean( ypred_SVMR != Y[ ,1])
error_SVMR
setwd("C:/Users/pnuka/OneDrive/Documents/Fall 2022/Research- Stat/GitHub/ADHD")
